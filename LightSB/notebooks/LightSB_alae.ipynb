{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea332904",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd716680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../ALAE\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from src.light_sb import LightSB\n",
    "from src.distributions import LoaderSampler, TensorSampler\n",
    "import deeplake\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from alae_ffhq_inference import load_model, encode, decode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e65eb",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13fd152",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 512\n",
    "assert DIM > 1\n",
    "\n",
    "INPUT_DATA = \"ADULT\" # MAN, WOMAN, ADULT, CHILDREN\n",
    "TARGET_DATA = \"CHILDREN\" # MAN, WOMAN, ADULT, CHILDREN\n",
    "\n",
    "OUTPUT_SEED = 0xBADBEEF\n",
    "BATCH_SIZE = 128\n",
    "EPSILON = 0.1\n",
    "D_LR = 1e-3 # 1e-3 for eps 0.1\n",
    "D_GRADIENT_MAX_NORM = float(\"inf\")\n",
    "N_POTENTIALS = 10\n",
    "SAMPLING_BATCH_SIZE = 128\n",
    "INIT_BY_SAMPLES = True\n",
    "IS_DIAGONAL = True\n",
    "\n",
    "MAX_STEPS = 10000\n",
    "CONTINUE = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = f'LightSB_ALAE_{INPUT_DATA}_TO_{TARGET_DATA}_EPSILON_{EPSILON}'\n",
    "OUTPUT_PATH = '../checkpoints/{}'.format(EXP_NAME)\n",
    "\n",
    "config = dict(\n",
    "    DIM=DIM,\n",
    "    D_LR=D_LR,\n",
    "    BATCH_SIZE=BATCH_SIZE,\n",
    "    EPSILON=EPSILON,\n",
    "    D_GRADIENT_MAX_NORM=D_GRADIENT_MAX_NORM,\n",
    "    N_POTENTIALS=N_POTENTIALS,\n",
    "    INIT_BY_SAMPLES=INIT_BY_SAMPLES,\n",
    "    IS_DIAGONAL=IS_DIAGONAL,\n",
    ")\n",
    "\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dcec61",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd2ad09",
   "metadata": {},
   "source": [
    "### TO DOWNLOAD PRE-PROCESSED ALAE DATA, UNCOMMENT THE CODE OF THE NEXT CELL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd56c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "\n",
    "urls = {\n",
    "    \"../data/age.npy\": \"https://drive.google.com/uc?id=1Vi6NzxCsS23GBNq48E-97Z9UuIuNaxPJ\",\n",
    "    \"../data/gender.npy\": \"https://drive.google.com/uc?id=1SEdsmQGL3mOok1CPTBEfc_O1750fGRtf\",\n",
    "    \"../data/latents.npy\": \"https://drive.google.com/uc?id=1ENhiTRsHtSjIjoRu1xYprcpNd8M9aVu8\",\n",
    "    \"../data/test_images.npy\": \"https://drive.google.com/uc?id=1SjBWWlPjq-dxX4kxzW-Zn3iUR3po8Z0i\",\n",
    "}\n",
    "\n",
    "for name, url in urls.items():\n",
    "    gdown.download(url, os.path.join(f\"{name}\"), quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d41b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To download data use\n",
    "\n",
    "train_size = 60000\n",
    "test_size = 10000\n",
    "\n",
    "latents = np.load(\"../data/latents.npy\")\n",
    "gender = np.load(\"../data/gender.npy\")\n",
    "age = np.load(\"../data/age.npy\")\n",
    "test_inp_images = np.load(\"../data/test_images.npy\")\n",
    "\n",
    "train_latents, test_latents = latents[:train_size], latents[train_size:]\n",
    "train_gender, test_gender = gender[:train_size], gender[train_size:]\n",
    "train_age, test_age = age[:train_size], age[train_size:]\n",
    "\n",
    "if INPUT_DATA == \"MAN\":\n",
    "    x_inds_train = np.arange(train_size)[(train_gender == \"male\").reshape(-1)]\n",
    "    x_inds_test = np.arange(test_size)[(test_gender == \"male\").reshape(-1)]\n",
    "elif INPUT_DATA == \"WOMAN\":\n",
    "    x_inds_train = np.arange(train_size)[(train_gender == \"female\").reshape(-1)]\n",
    "    x_inds_test = np.arange(test_size)[(test_gender == \"female\").reshape(-1)]\n",
    "elif INPUT_DATA == \"ADULT\":\n",
    "    x_inds_train = np.arange(train_size)[\n",
    "        (train_age >= 18).reshape(-1)*(train_age != -1).reshape(-1)\n",
    "    ]\n",
    "    x_inds_test = np.arange(test_size)[\n",
    "        (test_age >= 18).reshape(-1)*(test_age != -1).reshape(-1)\n",
    "    ]\n",
    "elif INPUT_DATA == \"CHILDREN\":\n",
    "    x_inds_train = np.arange(train_size)[\n",
    "        (train_age < 18).reshape(-1)*(train_age != -1).reshape(-1)\n",
    "    ]\n",
    "    x_inds_test = np.arange(test_size)[\n",
    "        (test_age < 18).reshape(-1)*(test_age != -1).reshape(-1)\n",
    "    ]\n",
    "x_data_train = train_latents[x_inds_train]\n",
    "x_data_test = test_latents[x_inds_test]\n",
    "\n",
    "if TARGET_DATA == \"MAN\":\n",
    "    y_inds_train = np.arange(train_size)[(train_gender == \"male\").reshape(-1)]\n",
    "    y_inds_test = np.arange(test_size)[(test_gender == \"male\").reshape(-1)]\n",
    "elif TARGET_DATA == \"WOMAN\":\n",
    "    y_inds_train = np.arange(train_size)[(train_gender == \"female\").reshape(-1)]\n",
    "    y_inds_test = np.arange(test_size)[(test_gender == \"female\").reshape(-1)]\n",
    "elif TARGET_DATA == \"ADULT\":\n",
    "    y_inds_train = np.arange(train_size)[\n",
    "        (train_age >= 18).reshape(-1)*(train_age != -1).reshape(-1)\n",
    "    ]\n",
    "    y_inds_test = np.arange(test_size)[\n",
    "        (test_age >= 18).reshape(-1)*(test_age != -1).reshape(-1)\n",
    "    ]\n",
    "elif TARGET_DATA == \"CHILDREN\":\n",
    "    y_inds_train = np.arange(train_size)[\n",
    "        (train_age < 18).reshape(-1)*(train_age != -1).reshape(-1)\n",
    "    ]\n",
    "    y_inds_test = np.arange(test_size)[\n",
    "        (test_age < 18).reshape(-1)*(test_age != -1).reshape(-1)\n",
    "    ]\n",
    "y_data_train = train_latents[y_inds_train]\n",
    "y_data_test = test_latents[y_inds_test]\n",
    "\n",
    "X_train = torch.tensor(x_data_train)\n",
    "Y_train = torch.tensor(y_data_train)\n",
    "\n",
    "X_test = torch.tensor(x_data_test)\n",
    "Y_test = torch.tensor(y_data_test)\n",
    "\n",
    "X_sampler = TensorSampler(X_train, device=\"cpu\")\n",
    "Y_sampler = TensorSampler(Y_train, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c22df8",
   "metadata": {},
   "source": [
    "# Model initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fce3c8",
   "metadata": {},
   "source": [
    "## LightSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e304d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(OUTPUT_SEED); np.random.seed(OUTPUT_SEED)\n",
    "\n",
    "D = LightSB(dim=DIM, n_potentials=N_POTENTIALS, epsilon=EPSILON,\n",
    "            sampling_batch_size=SAMPLING_BATCH_SIZE, S_diagonal_init=0.1,\n",
    "            is_diagonal=IS_DIAGONAL).cpu()\n",
    "\n",
    "if INIT_BY_SAMPLES:\n",
    "    D.init_r_by_samples(Y_sampler.sample(N_POTENTIALS))\n",
    "    \n",
    "D_opt = torch.optim.Adam(D.parameters(), lr=D_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b5901",
   "metadata": {},
   "source": [
    "## ALAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To download the required model run, run training_artifacts/download_all.py in the ALAE folder.\n",
    "\n",
    "model = load_model(\"../ALAE/configs/ffhq.yaml\", training_artifacts_dir=\"../ALAE/training_artifacts/ffhq/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c2b0f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wandb.init(name=EXP_NAME, config=config)\n",
    "\n",
    "for step in tqdm(range(CONTINUE + 1, MAX_STEPS)):\n",
    "    D_opt.zero_grad()\n",
    "    \n",
    "    X0, X1 = X_sampler.sample(BATCH_SIZE), Y_sampler.sample(BATCH_SIZE)\n",
    "    \n",
    "    log_potential = D.get_log_potential(X1)\n",
    "    log_C = D.get_log_C(X0)\n",
    "    \n",
    "    D_loss = (-log_potential + log_C).mean()\n",
    "    D_loss.backward()\n",
    "    D_gradient_norm = torch.nn.utils.clip_grad_norm_(D.parameters(), max_norm=D_GRADIENT_MAX_NORM)\n",
    "    D_opt.step()\n",
    "    \n",
    "    wandb.log({f'D gradient norm' : D_gradient_norm.item()}, step=step)\n",
    "    wandb.log({f'D_loss' : D_loss.item()}, step=step)\n",
    "         \n",
    "torch.save(D.state_dict(), os.path.join(OUTPUT_PATH, f'D.pt'))\n",
    "torch.save(D_opt.state_dict(), os.path.join(OUTPUT_PATH, f'D_opt.pt'))\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc14887a",
   "metadata": {},
   "source": [
    "# Results plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339e5793",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(OUTPUT_SEED); np.random.seed(OUTPUT_SEED)\n",
    "\n",
    "inds_to_map = np.random.choice(np.arange((x_inds_test < 300).sum()), size=10, replace=False)\n",
    "number_of_samples = 3\n",
    "\n",
    "mapped_all = []\n",
    "latent_to_map = torch.tensor(test_latents[x_inds_test[inds_to_map]])\n",
    "\n",
    "inp_images = test_inp_images[x_inds_test[inds_to_map]]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for k in range(number_of_samples):\n",
    "        mapped = D(latent_to_map.cpu())\n",
    "        mapped_all.append(mapped)\n",
    "    \n",
    "mapped = torch.stack(mapped_all, dim=1)\n",
    "\n",
    "decoded_all = []\n",
    "with torch.no_grad():\n",
    "    for k in range(number_of_samples):\n",
    "        decoded_img = decode(model, mapped[:, k])\n",
    "        decoded_img = ((decoded_img * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).permute(0, 2, 3, 1).numpy()\n",
    "        decoded_all.append(decoded_img)\n",
    "        \n",
    "decoded_all = np.stack(decoded_all, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94ec3c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, number_of_samples+1, figsize=(number_of_samples+1, 10), dpi=200)\n",
    "\n",
    "for i, ind in enumerate(range(10)):\n",
    "    ax = axes[i]\n",
    "    ax[0].imshow(inp_images[ind])\n",
    "    for k in range(number_of_samples):\n",
    "        ax[k+1].imshow(decoded_all[ind, k])\n",
    "        \n",
    "        ax[k+1].get_xaxis().set_visible(False)\n",
    "        ax[k+1].set_yticks([])\n",
    "        \n",
    "    ax[0].get_xaxis().set_visible(False)\n",
    "    ax[0].set_yticks([])\n",
    "\n",
    "fig.tight_layout(pad=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0983eefc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
