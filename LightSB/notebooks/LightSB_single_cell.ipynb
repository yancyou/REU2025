{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54873307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from TrajectoryNet.dataset import EBData\n",
    "\n",
    "from src.light_sb import LightSB\n",
    "from src.distributions import LoaderSampler, TensorSampler\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from TrajectoryNet.optimal_transport.emd import earth_mover_distance\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e4eac",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2772a4",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "DIM = 5\n",
    "assert DIM > 1\n",
    "\n",
    "SEED = 42\n",
    "BATCH_SIZE = 128\n",
    "EPSILON = 0.1\n",
    "D_LR = 1e-2\n",
    "D_GRADIENT_MAX_NORM = float(\"inf\")\n",
    "N_POTENTIALS = 100\n",
    "SAMPLING_BATCH_SIZE = 128\n",
    "INIT_BY_SAMPLES = True\n",
    "IS_DIAGONAL = True\n",
    "T = 1\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "MAX_STEPS = 2000\n",
    "CONTINUE = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c485eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "EPS = EPSILON\n",
    "EPSILON_END = EPSILON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af8b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP_NAME = f'Gaussians_Mixture_test_EPSILON_{EPSILON}_STEPS_{N_STEPS}_DIM_{DIM}'\n",
    "EXP_NAME = f'LightSB_cell_T_{T}_EPSILON_{EPSILON}_SEED_{SEED}'\n",
    "OUTPUT_PATH = '../checkpoints/{}'.format(EXP_NAME)\n",
    "\n",
    "config = dict(\n",
    "    DIM=DIM,\n",
    "    D_LR=D_LR,\n",
    "    BATCH_SIZE=BATCH_SIZE,\n",
    "    EPSILON=EPSILON,\n",
    "    D_GRADIENT_MAX_NORM=D_GRADIENT_MAX_NORM,\n",
    "    N_POTENTIALS=N_POTENTIALS,\n",
    "    INIT_BY_SAMPLES=INIT_BY_SAMPLES,\n",
    "    IS_DIAGONAL=IS_DIAGONAL,\n",
    "    SEED=SEED,\n",
    ")\n",
    "\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8ba029",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc87ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = EBData('pcs', max_dim=5)\n",
    "\n",
    "frame_0_start, frame_0_end = np.where(ds.labels == 0)[0][0], np.where(ds.labels == 0)[0][-1]\n",
    "frame_1_start, frame_1_end = np.where(ds.labels == 1)[0][0], np.where(ds.labels == 1)[0][-1]\n",
    "frame_2_start, frame_2_end = np.where(ds.labels == 2)[0][0], np.where(ds.labels == 2)[0][-1]\n",
    "frame_3_start, frame_3_end = np.where(ds.labels == 3)[0][0], np.where(ds.labels == 3)[0][-1]\n",
    "frame_4_start, frame_4_end = np.where(ds.labels == 4)[0][0], np.where(ds.labels == 4)[0][-1]\n",
    "\n",
    "X_mid_1 = ds.get_data()[frame_1_start:frame_1_end+1]\n",
    "X_mid_2 = ds.get_data()[frame_2_start:frame_2_end+1]\n",
    "X_mid_3 = ds.get_data()[frame_3_start:frame_3_end+1]\n",
    "\n",
    "if T == 1:\n",
    "    X_mid = X_mid_1\n",
    "    \n",
    "    X_0_f = ds.get_data()[frame_0_start:frame_0_end+1]\n",
    "    X_1_f = ds.get_data()[frame_2_start:frame_2_end+1]\n",
    "elif T == 2:\n",
    "    X_mid = X_mid_2\n",
    "    \n",
    "    X_0_f = ds.get_data()[frame_1_start:frame_1_end+1]\n",
    "    X_1_f = ds.get_data()[frame_3_start:frame_3_end+1] \n",
    "elif T == 3:\n",
    "    X_mid = X_mid_3\n",
    "    \n",
    "    X_0_f = ds.get_data()[frame_2_start:frame_2_end+1]\n",
    "    X_1_f = ds.get_data()[frame_4_start:frame_4_end+1]\n",
    "\n",
    "X_sampler = TensorSampler(torch.tensor(X_0_f).float(), device=\"cpu\")\n",
    "Y_sampler = TensorSampler(torch.tensor(X_1_f).float(), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f22ebe",
   "metadata": {},
   "source": [
    "## Model initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f127bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = LightSB(dim=DIM, n_potentials=N_POTENTIALS, epsilon=EPSILON,\n",
    "            sampling_batch_size=SAMPLING_BATCH_SIZE,\n",
    "            is_diagonal=IS_DIAGONAL).cpu()\n",
    "\n",
    "if INIT_BY_SAMPLES:\n",
    "    D.init_r_by_samples(Y_sampler.sample(N_POTENTIALS).to(DEVICE))\n",
    "    \n",
    "D_opt = torch.optim.Adam(D.parameters(), lr=D_LR)\n",
    "\n",
    "if CONTINUE > -1:\n",
    "    D_opt.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'D_opt_{SEED}_{CONTINUE}.pt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d1f42",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bc655c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wandb.init(name=EXP_NAME, config=config)\n",
    "\n",
    "for step in tqdm(range(CONTINUE + 1, MAX_STEPS)):\n",
    "    # training cycle\n",
    "    D_opt.zero_grad()\n",
    "    \n",
    "    X0, X1 = X_sampler.sample(BATCH_SIZE).to(DEVICE), Y_sampler.sample(BATCH_SIZE).to(DEVICE)\n",
    "    \n",
    "    log_potential = D.get_log_potential(X1)\n",
    "    log_C = D.get_log_C(X0)\n",
    "    \n",
    "    D_loss = (-log_potential + log_C).mean()\n",
    "    D_loss.backward()\n",
    "    D_gradient_norm = torch.nn.utils.clip_grad_norm_(D.parameters(), max_norm=D_GRADIENT_MAX_NORM)\n",
    "    D_opt.step()\n",
    "    \n",
    "    wandb.log({f'D gradient norm' : D_gradient_norm.item()}, step=step)\n",
    "    wandb.log({f'D_loss' : D_loss.item()}, step=step)\n",
    "    \n",
    "# eval and plots\n",
    "with torch.no_grad():\n",
    "    X = X_sampler.sample(X_0_f.shape[0]).to(DEVICE)\n",
    "    Y = Y_sampler.sample(X_1_f.shape[0]).to(DEVICE)\n",
    "\n",
    "    XN = D(X)\n",
    "\n",
    "    X_mid_pred = D.sample_at_time_moment(X, torch.ones(X.shape[0], 1)*0.5).detach().cpu().numpy()\n",
    "\n",
    "    EMD = earth_mover_distance(X_mid_pred, X_mid)\n",
    "\n",
    "    wandb.log({f'EMD_{T}' : EMD}, step=step)\n",
    "            \n",
    "torch.save(D.state_dict(), os.path.join(OUTPUT_PATH, f'D.pt'))\n",
    "torch.save(D_opt.state_dict(), os.path.join(OUTPUT_PATH, f'D_opt.pt'))\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400018f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
