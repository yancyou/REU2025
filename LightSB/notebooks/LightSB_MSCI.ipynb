{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc32ac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from src.light_sb import LightSB\n",
    "from src.distributions import LoaderSampler, TensorSampler\n",
    "from src.plotters import plot_2D\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import wandb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfbbf97",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6a076a",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "DIM = 1000\n",
    "assert DIM > 1\n",
    "\n",
    "SEED = 42\n",
    "BATCH_SIZE = 128\n",
    "EPSILON = 0.1\n",
    "D_LR = 1e-2\n",
    "D_GRADIENT_MAX_NORM = float(\"inf\")\n",
    "N_POTENTIALS = 10\n",
    "SAMPLING_BATCH_SIZE = 128\n",
    "INIT_BY_SAMPLES = True  \n",
    "IS_DIAGONAL = True\n",
    "DAY_START = 2\n",
    "DAY_END = 4\n",
    "DAY_EVAL = 3\n",
    "DEVICE = \"cpu\"\n",
    "EVAL_EVERY = 10000\n",
    "SERIES_ID = 1\n",
    "\n",
    "MAX_STEPS = 10000\n",
    "CONTINUE = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9271d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "EPS = EPSILON\n",
    "EPSILON_END = EPSILON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079a31c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = f'LightSB_old_Single_Cell_MAX_STEPS_{MAX_STEPS}_full_CITE_cell_DIM_{DIM}_DAY_EVAL_{DAY_EVAL}_EPSILON_{EPSILON}_SEED_{SEED}'\n",
    "OUTPUT_PATH = '../checkpoints/{}'.format(EXP_NAME)\n",
    "\n",
    "config = dict(\n",
    "    SERIES_ID=SERIES_ID,\n",
    "    DAY_START=DAY_START,\n",
    "    DAY_END=DAY_END,\n",
    "    DAY_EVAL=DAY_EVAL,\n",
    "    DIM=DIM,\n",
    "    D_LR=D_LR,\n",
    "    BATCH_SIZE=BATCH_SIZE,\n",
    "    EPSILON=EPSILON,\n",
    "    D_GRADIENT_MAX_NORM=D_GRADIENT_MAX_NORM,\n",
    "    N_POTENTIALS=N_POTENTIALS,\n",
    "    INIT_BY_SAMPLES=INIT_BY_SAMPLES,\n",
    "    IS_DIAGONAL=IS_DIAGONAL,\n",
    "    SEED=SEED,\n",
    ")\n",
    "\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532c4561",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f35d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for day in [2, 3, 4, 7]:\n",
    "    data[day] = np.load(f\"../data/full_cite_pcas_{DIM}_day_{day}.npy\")\n",
    "    \n",
    "eval_data = data[DAY_EVAL]\n",
    "start_data = data[DAY_START]\n",
    "end_data = data[DAY_END]\n",
    "\n",
    "constant_scale = np.concatenate([start_data, end_data, eval_data]).std(axis=0).mean()\n",
    "\n",
    "eval_data_scaled = eval_data/constant_scale\n",
    "start_data_scaled = start_data/constant_scale\n",
    "end_data_scaled = end_data/constant_scale\n",
    "\n",
    "eval_data = torch.tensor(eval_data).float()\n",
    "start_data = torch.tensor(start_data_scaled).float()\n",
    "end_data = torch.tensor(end_data_scaled).float()\n",
    "\n",
    "X_sampler = TensorSampler(torch.tensor(start_data).float(), device=\"cpu\")\n",
    "Y_sampler = TensorSampler(torch.tensor(end_data).float(), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc945c0",
   "metadata": {},
   "source": [
    "## Model initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa62b6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = LightSB(dim=DIM, n_potentials=N_POTENTIALS, epsilon=EPSILON,\n",
    "            sampling_batch_size=SAMPLING_BATCH_SIZE,\n",
    "            is_diagonal=IS_DIAGONAL).cpu()\n",
    "\n",
    "if INIT_BY_SAMPLES:\n",
    "    D.init_r_by_samples(Y_sampler.sample(N_POTENTIALS).to(DEVICE))\n",
    "    \n",
    "D_opt = torch.optim.Adam(D.parameters(), lr=D_LR)\n",
    "\n",
    "if CONTINUE > -1:\n",
    "    D_opt.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'D_opt_{SEED}_{CONTINUE}.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf0a09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmd(x, y):\n",
    "    Kxx = pairwise_distances(x, x)\n",
    "    Kyy = pairwise_distances(y, y)\n",
    "    Kxy = pairwise_distances(x, y)\n",
    "\n",
    "    m = x.shape[0]\n",
    "    n = y.shape[0]\n",
    "    \n",
    "    c1 = 1 / ( m * (m - 1))\n",
    "    A = np.sum(Kxx - np.diag(np.diagonal(Kxx)))\n",
    "\n",
    "    # Term II\n",
    "    c2 = 1 / (n * (n - 1))\n",
    "    B = np.sum(Kyy - np.diag(np.diagonal(Kyy)))\n",
    "\n",
    "    # Term III\n",
    "    c3 = 1 / (m * n)\n",
    "    C = np.sum(Kxy)\n",
    "\n",
    "    # estimate MMD\n",
    "    mmd_est = -0.5*c1*A - 0.5*c2*B + c3*C\n",
    "    \n",
    "    return mmd_est"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494bc6f7",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec8ca69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wandb.init(name=EXP_NAME, config=config, project=\"LightSBplus\")\n",
    "\n",
    "for step in tqdm(range(CONTINUE + 1, MAX_STEPS)):\n",
    "    # training cycle\n",
    "    D_opt.zero_grad()\n",
    "    \n",
    "    X0, X1 = X_sampler.sample(BATCH_SIZE).to(DEVICE), Y_sampler.sample(BATCH_SIZE).to(DEVICE)\n",
    "    \n",
    "    log_potential = D.get_log_potential(X1)\n",
    "    log_C = D.get_log_C(X0)\n",
    "    \n",
    "    D_loss = (-log_potential + log_C).mean()\n",
    "    D_loss.backward()\n",
    "    D_gradient_norm = torch.nn.utils.clip_grad_norm_(D.parameters(), max_norm=D_GRADIENT_MAX_NORM)\n",
    "    D_opt.step()\n",
    "    \n",
    "    wandb.log({f'D gradient norm' : D_gradient_norm.item()}, step=step)\n",
    "    wandb.log({f'D_loss_minibatch' : D_loss.item()}, step=step)\n",
    "\n",
    "    # eval and plots\n",
    "    if (step + 1) % EVAL_EVERY == 0:\n",
    "        with torch.no_grad():\n",
    "            X = X_sampler.sample(start_data.shape[0]).to(DEVICE)\n",
    "            Y = Y_sampler.sample(end_data.shape[0]).to(DEVICE)\n",
    "            \n",
    "            XN = D(X)\n",
    "            XN_pred = XN.detach().cpu().numpy()*constant_scale\n",
    "            \n",
    "            MMD_target = mmd(XN_pred, end_data*constant_scale)\n",
    "            wandb.log({f'MMD_target' : MMD_target}, step=step)\n",
    "\n",
    "            X_mid_pred = D.sample_at_time_moment(X, torch.ones(X.shape[0], 1)*(DAY_EVAL - DAY_START)/(DAY_END-DAY_START)).detach().cpu().numpy()\n",
    "            X_mid_pred = X_mid_pred*constant_scale\n",
    "            \n",
    "            MMD = mmd(X_mid_pred, eval_data)\n",
    "            wandb.log({f'MMD' : MMD}, step=step)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df52cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a434a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
